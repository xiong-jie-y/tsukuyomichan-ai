# manuscript = [
#     "こんにちは、フリー素材キャラクターつくよみの非公式AIです。",
#     0.8,
#     "私、最近、文章読み動画を作ることができるようになりました。",
#     0.8,
#     "文章を用意していただければ、読み上げて動画にします。",
#     0.3,
#     "読み上げ内容に合わせて、口を動かしたり、表情を変えたりもできます。",
#     0.5, 
#     "例えば",
#     0.5, 
#     "むかつく",
#     0.3, 
#     "というように怒りの表現であれば、怒った表情になり",
#     0.3,
#     "今日のカレーは美味しかった",
#     0.3,
#     "というようにハッピーな表現であれば、ハッピーな表情になります。",
#     0.3,
#     "この動画も文章を元に自動的に私が作りました。",
#     1.0
# ]

manuscript = """
Talking Head Anime 2とは、一枚のキャラクターの顔画像のみを用いてキャラクターの口や目や眉毛を動かせる技術です。
Githubでオープンソースで公開されています。
"""

manuscript = """
これは、超解像モデルの中でもそこそこ動く、Real ESRGAN、FastSRGAN、Realtime Super ResolutionをBicubic補完を使った拡大結果です。
実行速度はRTX 3070のPCで測定しました。
アニメ画像の場合、Real ESRGANは非常にきれいに拡大してくれました。
実行速度は10fps前後で、キャラクターのモーションをリアルタイムで表示するには厳しく、動画生成など、非リアルタイム処理に用いました。
FastSRGANはBicubicよりましですが、若干ぼやけています。
ただ、30fpsで動かすことができるため、512×512に縮小してリアルタイム処理に利用しました。
Realtime Super Resolutionは実行速度が遅い割には、そんなにきれいではなかったため、今回は使いませんでした。
1.5
また、さらなる高速化を目指し、ONNX化とgraph optimizationも試してみました。
ONNX化したモデルでは、消費ビデオメモリ量が数百から1GB増え、実行速度はあまり変わりませんでした。
ORT化などさらなる最適化をかけた場合は実行速度が低下しました。
これ以上の速度改善には今の所成功していません。
"""